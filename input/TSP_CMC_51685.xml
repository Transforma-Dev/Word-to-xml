<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="style/jpub3-html-trans.xsl"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.0 20120330//EN" "D:/Localserver/Apache/htdocs/Transforma/ce_editor/Conversion/Word2HTML/DTD/jats-publishing-dtd-1.0/JATS-journalpublishing1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="research-article" dtd-version="1.0">
<front>
<journal-meta>
<journal-id journal-id-type="pmc">CMC</journal-id>
<journal-id journal-id-type="nlm-ta">CMC</journal-id>
<journal-id journal-id-type="publisher-id">CMC</journal-id>
<journal-title-group>
<journal-title>Computers, Materials &#x0026; Continua</journal-title>
</journal-title-group>
<issn pub-type="epub">1546-2226</issn>
<issn pub-type="ppub">1546-2218</issn>
<publisher>
<publisher-name>Tech Science Press</publisher-name>
<publisher-loc>USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">51685</article-id>
<article-id pub-id-type="doi">10.32604/cmc.2024.051685</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Article</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>MUS Model: A Deep Learning-Based Architecture for IoT Intrusion Detection</article-title>
<alt-title alt-title-type="left-running-head">MUS Model: A Deep Learning-Based Architecture for IoT Intrusion Detection</alt-title>
<alt-title alt-title-type="right-running-head">MUS Model: A Deep Learning-Based Architecture for IoT Intrusion Detection</alt-title>
</title-group>
<contrib-group content-type="authors">
<contrib id="author-1" contrib-type="author">
<name name-style="western"><surname>Yan</surname><given-names>Yu</given-names></name><xref ref-type="aff" rid="aff-1">1</xref></contrib>
<contrib id="author-2" contrib-type="author" corresp="yes">
<name name-style="western"><surname>Yang</surname><given-names>Yu</given-names></name><xref ref-type="aff" rid="aff-1">1</xref><email>aa18634816079@163.com</email></contrib>
<contrib id="author-3" contrib-type="author">
<name name-style="western"><surname>Fang</surname><given-names>Shen</given-names></name><xref ref-type="aff" rid="aff-1">1</xref></contrib>
<contrib id="author-4" contrib-type="author">
<name name-style="western"><surname>Gao</surname><given-names>Minna</given-names></name><xref ref-type="aff" rid="aff-2">2</xref></contrib>
<contrib id="author-5" contrib-type="author">
<name name-style="western"><surname>Chen</surname><given-names>Yiding</given-names></name><xref ref-type="aff" rid="aff-1">1</xref></contrib>
<aff id="aff-1"><label>1</label><institution>College of Information Engineering, University of Engineering of the Chinese People&#x2019;s Armed Police Force (PAP)</institution>, <addr-line>Xi&#x2019;an, 710000</addr-line>, <country>China</country></aff>
<aff id="aff-2"><label>2</label><institution>College of Missile Engineering, Rocket Force Engineering University</institution>, <addr-line>Xi&#x2019;an, 710000</addr-line>, <country>China</country></aff>
</contrib-group>
<author-notes>
<corresp id="cor1">&#x002A;Corresponding Author: Yu Yang. Email: <email>aa18634816079@163.com</email></corresp>
</author-notes>
<pub-date pub-type="epub" date-type="pub" iso-8601-date="2024-05-29">
<day>29</day>
<month>xxx</month>
<year>2024</year>
</pub-date>
<volume>XX</volume>
<issue>XX</issue>
<fpage>XX</fpage>
<lpage>XX</lpage>
<history>
<date date-type="received">
<day>12</day>
<month>3</month>
<year>2024</year>
</date>
<date date-type="accepted">
<day>16</day>
<month>5</month>
<year>2024</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2024 Yan et al.</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Yan et al.</copyright-holder>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:type="simple" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="TSP_CMC_51685.pdf"></self-uri>
<abstract>
<p>In the face of the effective popularity of the Internet of Things (IoT), but the frequent occurrence of cybersecurity incidents, various cybersecurity protection means have been proposed and applied. Among them, Intrusion Detection System (IDS) has been proven to be stable and efficient. However, traditional intrusion detection methods have shortcomings such as low detection accuracy and inability to effectively identify malicious attacks. To address the above problems, this paper fully considers the superiority of deep learning models in processing high-dimensional data, and reasonable data type conversion methods can extract deep features and detect classification using advanced computer vision techniques to improve classification accuracy. The Markov Transform Field (MTF) method is used to convert 1D network traffic data into 2D images, and then the converted 2D images are filtered by Unsharp Masking to enhance the image details by sharpening; to further improve the accuracy of data classification and detection, unlike using the existing high-performance baseline image classification models, a soft-voting integrated model, which integrates three deep learning models, MobileNet, VGGNet and ResNet, to finally obtain an effective IoT intrusion detection architecture: the MUS model. Four types of experiments are conducted on the publicly available intrusion detection dataset CICIDS2018 and the IoT network traffic dataset N_BaIoT, and the results demonstrate that the accuracy of attack traffic detection is greatly improved, which is not only applicable to the IoT intrusion detection environment, but also to different types of attacks and different network environments, which confirms the effectiveness of the work done.</p>
</abstract>
<kwd-group kwd-group-type="author">
<kwd>Cyberspace security</kwd>
<kwd>intrusion detection</kwd>
<kwd>deep learning</kwd>
<kwd>markov transition fields (MTF)</kwd>
<kwd>soft voting integration</kwd>
</kwd-group>
<counts>
<page-count count="0"/>
</counts>
</article-meta>
</front>
<body>
<sec id="s1">
<label>1</label>
<title>Introduction</title>
<p>With the development of the Internet, computer technology [<xref ref-type="bibr" rid="ref-1">1</xref>] has penetrated into all aspects of human production and life. From food, clothing, housing and transport to mobile payments, from smart homes to drones, especially the emergence and popularity of IoT [<xref ref-type="bibr" rid="ref-2">2</xref>] has created a new situation of interconnecting everything, becoming an indispensable bridge connecting the digital world and the physical world. It collects, analyses and utilizes heterogeneous data through the interconnectivity of different devices to achieve seamless communication between systems, platforms and humans, thus assisting in the generation of smarter decisions (<?A3B2 "fig1",5,"anchor"?><xref ref-type="fig" rid="fig-1">Fig. 1</xref>).</p>
<fig id="fig-1">
<label>Figure 1</label>
<caption>
<title>Examples of IoT components</title>
</caption>
<graphic mimetype="image" mime-subtype="tif" xlink:href="CMC_51685-fig-1.tif"/>
</fig>
<p>However, due to the diversity and differences between smart devices belonging to IoT, and the layered, seamless, and unstable nature of the network structure, security is facing serious challenges, which are highlighted by the frequent occurrence of malicious attacks, which are harmful. 20 In October 2023 genetic testing provider 23 and Me suffered from a crash attack that led to the leakage of 6.9 million users&#x2019; data, which was described as the &#x201C;the worst medical data breach&#x201D;; on 8 November 2023, ICBC Financial Services LLC (ICBCFS), a wholly-owned US subsidiary of the Industrial and Commercial Bank of China (ICBC), was hit by a LockBit ransomware [<xref ref-type="bibr" rid="ref-3">3</xref>] attack that was launched using the Citrix Bleed vulnerability that was not patched in time attack, resulting in partial system disruption and affecting normal business. The occurrence of the above security incidents is not coincidental, the &#x201C;2022 Annual Cyberspace Mapping Report&#x201D; shows that the number of exposed smart connected devices such as cameras, routers, VoIP phones, etc., in 2022 have all exceeded 2 million units, which has a very high risk of information leakage, and this has directly led to the development and expansion of the market for IoT security industry [<xref ref-type="bibr" rid="ref-4">4</xref>] (<?A3B2 "fig2",5,"anchor"?><xref ref-type="fig" rid="fig-2">Fig. 2</xref>).</p>
<fig id="fig-2">
<label>Figure 2</label>
<caption>
<title>IoT security industry market trend chart</title>
</caption>
<graphic mimetype="image" mime-subtype="tif" xlink:href="CMC_51685-fig-2.tif"/>
</fig>
<p>In the face of severe IoT network security problems, a complete IoT network security system [<xref ref-type="bibr" rid="ref-5">5</xref>] has been proposed (<?A3B2 "fig3",5,"anchor"?><xref ref-type="fig" rid="fig-3">Fig. 3</xref>).</p>
<fig id="fig-3">
<label>Figure 3</label>
<caption>
<title>Internet of things network security system architecture</title>
</caption>
<graphic mimetype="image" mime-subtype="tif" xlink:href="CMC_51685-fig-3.tif"/>
</fig>
<p>In order to achieve the solidity of the system and give full play to the system&#x2019;s role, this paper starts the research from the bottom structure-security protection [<xref ref-type="bibr" rid="ref-6">6</xref>]. However, traditional network security protection means, such as data encryption [<xref ref-type="bibr" rid="ref-7">7</xref>], traceability analysis, firewall [<xref ref-type="bibr" rid="ref-8">8</xref>], access control [<xref ref-type="bibr" rid="ref-9">9</xref>], anti-virus wall, user authorization [<xref ref-type="bibr" rid="ref-10">10</xref>], etc., belong to the negative means of passive defence, and it is difficult to provide comprehensive security protection. Therefore, the active means of protection-intrusion detection technology urgently needs to be used, which focuses on the internal data, external data and misuse of active detection and early warning, to provide decision-making basis for operations and maintenance personnel. Although the current research for intrusion detection [<xref ref-type="bibr" rid="ref-11">11</xref>] technology is being carried out one after another, machine learning, deep learning and other artificial intelligence technology to make the detection performance greatly improved. However, it is far from enough for the network anomaly traffic detection which requires very high accuracy and costly false alarms, with the following problems:
<list list-type="simple">
<list-item><label>(1)</label><p>Directly using low-dimensional deep learning models to learn, train and test one-dimensional network traffic data, ignoring the superiority of deep learning in extracting complex features;</p></list-item>
<list-item><label>(2)</label><p>Lacking the necessary and efficient feature extraction and further processing of network traffic data after simple preprocessing, which substantially affects the detection accuracy;</p></list-item>
<list-item><label>(3)</label><p>Directly using baseline machine learning or deep learning models to detect and classify network traffic, which is highly dependent on the quality and diversity of the training dataset, with low model robustness and detection accuracy.</p></list-item>
</list></p>
<p>In order to further improve the detection accuracy of the IoT intrusion detection framework, this paper conducts research on the above issues, with the following main contributions:
<list list-type="simple">
<list-item><label>(1)</label><p>The MTF method is proposed to convert one-dimensional network traffic data into two-dimensional images, using Recurrent Neural Networks (RNN) instead of frequency counts to estimate the transfer probability, automatically learning the complex relationship between different states, accurately capturing the key features of the data, and having a stronger semantic understanding capability;</p></list-item>
<list-item><label>(2)</label><p>Adopt Unsharp Masking filter to sharpen the converted 2D image, so as to enhance the image details and lay a good foundation for the next step of image classification and detection;</p></list-item>
<list-item><label>(3)</label><p>Propose to construct an image classification model using the soft voting integration method to improve the detection accuracy, select three efficient baseline deep learning models for image classification: MobileNet, VGGNet, and ResNet, perform soft voting integration, and use the merged integrated model AVR Model to detect the image, which greatly improves the detection accuracy;</p></list-item>
<list-item><label>(4)</label><p>Construct a MUS intrusion detection framework for IoT using MTF method and deep learning models. Three types of experiments are conducted on two datasets: N_BaIoT, and CICIDS2018, respectively, and the results prove that the detection accuracy of the proposed framework is substantially improved and is effective on IoT.</p></list-item>
</list></p>
<p>The line structure of this paper is as follows: <xref ref-type="sec" rid="s2">Section 2</xref> is the related work, including an overview comparison of research on intrusion detection techniques, data processing and integration methods; <xref ref-type="sec" rid="s3">Section 3</xref> is the methodology, including a detailed description of the MTF method, the improved Unsharp Masking filtering method, and the baseline image classification model soft-voting integration method, which ultimately constitutes the intrusion detection framework, MUS; and <xref ref-type="sec" rid="s4">Section 4</xref> is the implementation of the experiments. It includes a description of the dataset, experimental environment, setup conditions and process to demonstrate the effectiveness of the work done; <xref ref-type="sec" rid="s5">Section 5</xref> is the conclusion and outlook, which aims to summarize this paper and look forward to the future, providing a reference basis for researchers in related fields.</p>
</sec>
<sec id="s2">
<label>2</label>
<title>Related Work</title>
<sec id="s2_1">
<label>2.1</label>
<title>Intrusion Detection Systems (IDS)</title>
<p>Since Anderson first proposed the concept of intrusion detection in 1980 [<xref ref-type="bibr" rid="ref-12">12</xref>], the research of intrusion detection technology has become a hot spot in the field of network security protection, and the related researches have emerged and developed rapidly. Especially after Hinton et al. [<xref ref-type="bibr" rid="ref-13">13</xref>] proposed deep neural networks in 2006, along with the arithmetic power improvement of hardware devices and the surge of data volume, machine learning and deep learning algorithms have been widely used in the field of intrusion detection and achieved good results. Farooq et al. in their research [<xref ref-type="bibr" rid="ref-14">14</xref>] proposed a fusion intrusion detection framework based on machine learning, IDS-FMLT, for a heterogeneous network composed of heterogeneous networks composed of different source networks, and experiments proved that the detection accuracy of this framework on the training and validation sets can reach 96.73% and 95.18%, respectively, which significantly improves the detection accuracy; Qazi et al. in their research [<xref ref-type="bibr" rid="ref-15">15</xref>] proposed an intrusion detection based on convolutional neural network (CNN) and recurrent neural network (RNN) for the problem of difficulty in acquiring and analyzing the local features of the data, and proposed a convolutional neural network (CNN) and recurrent neural network (RNN) based intrusion detection system HDLNIDS, and achieved an average accuracy of up to 98.90% on the public dataset CICIDS2018; In their research [<xref ref-type="bibr" rid="ref-16">16</xref>], Xie et al. proposed an anomaly detection method based on Multi-Granularity Neighbourhood Residual Network (MGNRN) for the problem of difficult to obtain sample features comprehensively in the time series data, which was proved by experiments to significantly improve the detection accuracy on the task scenarios, especially on F1-Score, and provide a high-value method for the difficulty of deep feature extraction in time series. Yin et al. in their research [<xref ref-type="bibr" rid="ref-17">17</xref>] constructed an intrusion detection framework based on virtual fusion data for the IoT security problem, fused machine learning and deep convolutional neural network algorithm (DCNN), and proposed a new loss function with full consideration of user privacy protection, and the detection accuracy is up to 96.5% on the NSL-KDD dataset. The above studies make full use of the advantages of deep learning in feature analysis and learning, and they all achieve good detection results. However, they neglect the potential and effectiveness of deep learning models in extracting high-dimensional features, and all of them directly detect and classify one-dimensional network traffic, which can&#x2019;t fully exploit the superiority of deep learning algorithms in terms of detection accuracy. Therefore, due to the above considerations, this paper adopts the MTF method, which converts one-dimensional network traffic into two-dimensional images, and combines the classical filtering method and the efficient image classification model to obtain higher detection accuracy and improve the level of IoT network security protection.</p>
</sec>
<sec id="s2_2">
<label>2.2</label>
<title>Data Processing</title>
<p>Data processing usually refers to numerical, normalization, feature extraction, feature dimensionality reduction and other operations on the collected data to clean the &#x201C;dirty&#x201D; data into &#x201C;clean&#x201D; data, laying the foundation for subsequent detection and classification. However, the arrival of the big data era has led to a surge in the amount of heterogeneous data from multiple sources, and the traditional simple data processing is no longer sufficient to effectively detect malicious traffic attacks. Therefore, a number of studies have made special processing of 1D network traffic before detection and classification, such as converting data types, feature engineering processing, etc. Terzi in their research [<xref ref-type="bibr" rid="ref-18">18</xref>] emphasised the superiority of the visual interpretation capability of deep learning algorithms and used the Gram&#x2019;s Angle Field method (GAF) to convert 1D data to 2D images and classify the images using CNN, with a detection accuracy of up to 1.0% on the CICIDS2017 The detection accuracy on the dataset is up to 99.33%; Baldini et al. in their research [<xref ref-type="bibr" rid="ref-19">19</xref>] used Grey Level Co-occurrence Matrix (GLCM) and 2D Dispersion Entropy to convert 1D data into 2D grey scale maps, and later used the detection bias of machine learning algorithms to achieve an Error Rate (ER) of as low as 0.16% on the CICIDS2017 dataset; Siddiqi et al. in their research [<xref ref-type="bibr" rid="ref-20">20</xref>] proposed improved DeepInsight-based approach and Kernel Principal Component Analysis (KPCA) method to convert one-dimensional data into two-dimensional images, and after data augmentation, a deep learning classifier was used to classify the images on CSE- CIC-IDS 2018 and other three types of datasets experimentally proved to have high detection accuracy. All of the above studies convert one-dimensional network traffic into two-dimensional images for detection and classification, which not only allows the data to present more features and diversity, which is conducive to the model to better capture different types of network traffic behaviours; they also make use of the mature image processing techniques in the fields of computer vision and deep learning to better learn and train the model, and further improve the detection accuracy of malicious traffic. However, they only focus on image conversion using traditional data processing methods, while ignoring the way and accuracy of feature extraction, and the effective data information is not retained, converted and utilised on a large scale. Therefore, in this paper, we adopt the MTF method for image conversion, which can maximise the retention of sequence information, reduce the data dimensions, enhance local features, and help the deep learning model to better capture the key details related to intrusion.</p>
</sec>
<sec id="s2_3">
<label>2.3</label>
<title>Ensemble Learning</title>
<p>Ensemble Learning (EL) [<xref ref-type="bibr" rid="ref-21">21</xref>] is a learning method that accomplishes a learning task by combining multiple underlying learners. It uses a set of complementary learners for prediction, combining their outputs appropriately to improve the generalisation ability of the model, reduce the risk of overfitting, and in some cases produce better performance than the individual learners, and is now widely used in the field of intrusion detection. In their research [<xref ref-type="bibr" rid="ref-22">22</xref>], Shen et al. constructed a class-level soft-voting integration scheme (CBA-CLSVE) combining Chaos Bat Algorithm (CBA) with Support Vector Machines (SVM), K Nearest Neighbours (KNN), and Decision Trees (DTs) as the base learners, and experimentally proved the scheme to be effective on NSL-KDD, UNSW-NB15, and CICIDS2017 datasets; Alshede et al. in their research [<xref ref-type="bibr" rid="ref-23">23</xref>] developed a Random Forest (RF) and Convolutional Neural Network (CNN) based integrated voting method, and experimentally achieved up to 98.29% accuracy on the CICIDS2017 dataset, which is a significant increase in accuracy compared to other baseline models; Albashish et al. proposed a heterogeneous integrated classifier combining multiple baseline machine learning models and weighted majority voting in their research [<xref ref-type="bibr" rid="ref-24">24</xref>], and performed five classifications on the NSL-KDD dataset, and experimentally proved that the overall classification accuracy has been significantly improved. As shown in <?A3B2 "tbl1",5,"anchor"?><xref ref-type="table" rid="table-1">Table 1</xref>, the above study proves that integrated learning can effectively improve the detection accuracy of baseline deep learning models in intrusion detection, especially the soft voting integration method. Therefore, in this paper, on the basis of selecting three types of high-performing baseline image classification models: MobileNet, VGGNet and ResNet, we adjust the parameters and construct a soft-voting integration framework to improve the classification accuracy of abnormal traffic.</p>
<table-wrap id="table-1">
<label>Table 1</label>
<caption>
<title>Relevant studies conducted on IoT intrusion detection</title>
</caption>
<alternatives>
<graphic mimetype="image" mime-subtype="tif" xlink:href="table-1.tif"/>
<table>
<colgroup>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<thead>
<tr>
<th>Related work</th>
<th>Proposed algorithm</th>
<th>Dataset</th>
<th>With or without data processing</th>
<th>With or without integration</th>
<th>Accuracy</th>
<th>Year</th>
</tr>
</thead>
<tbody>
<tr>
<td rowspan="2">[<xref ref-type="bibr" rid="ref-14">14</xref>]</td>
<td rowspan="2">IDS-FMLT</td>
<td>KDD-CUP99</td>
<td rowspan="2">&#x00D7;</td>
<td rowspan="2">&#x00D7;</td>
<td rowspan="2">95.18%</td>
<td rowspan="2">2023</td>
</tr>
<tr>
<td>NetML-2020</td>
</tr>
<tr>
<td>[<xref ref-type="bibr" rid="ref-15">15</xref>]</td>
<td>HDLNIDS</td>
<td>CICIDS2018</td>
<td>&#x2713;</td>
<td>&#x00D7;</td>
<td>98.90%</td>
<td>2023</td>
</tr>
<tr>
<td>[<xref ref-type="bibr" rid="ref-16">16</xref>]</td>
<td>MGNRN</td>
<td>three UCI datasets</td>
<td>&#x2713;</td>
<td>&#x00D7;</td>
<td>99.20%</td>
<td>2022</td>
</tr>
<tr>
<td>[<xref ref-type="bibr" rid="ref-17">17</xref>]</td>
<td>RNN, DCNN cloud-based loss function</td>
<td>NSL-KDD</td>
<td>&#x2713;</td>
<td>&#x00D7;</td>
<td>96.50%</td>
<td>2023</td>
</tr>
<tr>
<td>[<xref ref-type="bibr" rid="ref-18">18</xref>]</td>
<td>GAF &#x002B; CNN</td>
<td>CICIDS2017</td>
<td>&#x2713;</td>
<td>&#x00D7;</td>
<td>99.33%</td>
<td>2022</td>
</tr>
<tr>
<td>[<xref ref-type="bibr" rid="ref-19">19</xref>]</td>
<td>GLCM the 2D dispersion entropy</td>
<td>CICIDS2017</td>
<td>&#x2713;</td>
<td>&#x00D7;</td>
<td>0.16% (Error rate)</td>
<td>2021</td>
</tr>
<tr>
<td rowspan="3">[<xref ref-type="bibr" rid="ref-20">20</xref>]</td>
<td rowspan="3">DeepInsight-based kernel principal component analysis (KPCA) CNN</td>
<td rowspan="3">CSE-CIC-IDS 2018, CIC-IDS 2017, ISCX-IDS 2012</td>
<td rowspan="3">&#x2713;</td>
<td rowspan="3">&#x00D7;</td>
<td>97.75%</td>
<td rowspan="3">2022</td>
</tr>
<tr>
<td>98.79%</td>
</tr>
<tr>
<td>92.92%</td>
</tr>
<tr>
<td rowspan="3">[<xref ref-type="bibr" rid="ref-22">22</xref>]</td>
<td rowspan="3">CBA-CLSVE</td>
<td>NSL-KDD</td>
<td rowspan="3">&#x00D7;</td>
<td rowspan="3">&#x2713;</td>
<td>97.50%</td>
<td rowspan="3">2022</td>
</tr>
<tr>
<td>UNSW-NB15</td>
<td>94.73%</td>
</tr>
<tr>
<td>CICIDS2017</td>
<td>99.75%</td>
</tr>
<tr>
<td>[<xref ref-type="bibr" rid="ref-23">23</xref>]</td>
<td>ADS</td>
<td>CICIDS2017</td>
<td>&#x00D7;</td>
<td>&#x2713;</td>
<td>98.29%</td>
<td>2023</td>
</tr>
<tr>
<td>[<xref ref-type="bibr" rid="ref-24">24</xref>]</td>
<td>ACOR-WMV</td>
<td>NSL-KDD</td>
<td>&#x00D7;</td>
<td>&#x2713;</td>
<td>83.43%</td>
<td>2022</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
</sec>
</sec>
<sec id="s3">
<label>3</label>
<title>Methodology</title>
<p>In order to give full play to the superiority of deep learning models in high-dimensional data learning and testing, and to further improve the accuracy of anomalous traffic detection and classification, it is different from the traditional research in which one-dimensional network traffic data are directly subjected to feature learning, training and classification. In this paper, we focus on the application of deep learning models on 2D images, using MTF method to convert 1D network traffic data into 2D images, and then using Unsharp Masking filter to sharpen the image to enhance the details, and finally constructing a soft-voting integration framework consisting of three types of baseline image classification models, namely MobileNet, VGGNet, and ResNet. The processed images are inputted into the integrated intrusion detection framework with high detection accuracy to obtain accurate classification of benign and abnormal traffic (<?A3B2 "fig4",5,"anchor"?><xref ref-type="fig" rid="fig-4">Fig. 4</xref>).</p>
<fig id="fig-4">
<label>Figure 4</label>
<caption>
<title>Intrusion detection integration framework</title>
</caption>
<graphic mimetype="image" mime-subtype="tif" xlink:href="CMC_51685-fig-4.tif"/>
</fig>
<sec id="s3_1">
<label>3.1</label>
<title>MTF [<xref ref-type="bibr" rid="ref-25">25</xref>]&#x2014;for Data Type Conversions</title>
<p>MTF is a data type conversion method based on Markov stochastic process, belongs to the first step in the constructed intrusion detection framework for data type conversion, which regards the one-dimensional time series to be converted as a set of data conforming to the Markov stochastic process, i.e., the current state is related to the previous state only, and is not related to other previous states. Based on the above theory a Markov matrix can be constructed to expand the time series into a Markov transfer field, thus realizing the conversion of data types.</p>
<p>Taking a set of benign network traffic in the CICIDS2018 dataset as an example, the process can be briefly described as follows: the first step is to divide the one-dimensional time series X &#x003D; {x<sub>1</sub>,x<sub>2</sub>,......,x<sub>n</sub>} into Q bins Q &#x003D; {q<sub>1</sub>,q<sub>2</sub>,......,q<sub>n</sub>}, which serves to discretize the data; at the same time, the time series data can also be mapped into the Q quantile bins, which facilitates the subsequent transformation into Markov matrices; the second step is to construct the Markov transfer matrix W (<xref ref-type="disp-formula" rid="eqn-1">Eq. (1)</xref>).
<disp-formula id="eqn-1"><label>(1)</label><alternatives><graphic mimetype="image" mime-subtype="tif" xlink:href="eqn-1.tif"/><tex-math id="tex-eqn-1"><![CDATA[\begin{equation}{\textrm W}=\left[\begin{array}{ccc} w_{11} & \cdots & w_{1Q}\\ \vdots & \ddots & \vdots \\ w_{Q1} & \cdots & w_{QQ} \end{array}\right],\mathrm{s}.\mathrm{t}.\sum _{j}w_{ij}=1\end{equation}]]></tex-math><mml:math id="mml-eqn-1" display="block"></mml:math></alternatives></disp-formula>where w<sub>ij</sub> denotes the frequency of transfer of data from quartile box i to quartile box j. In this case, frequency counts or frequency statistics are usually used to estimate the transfer probability. For example, using maximum likelihood estimation or frequency statistics, the transfer probability is estimated based on the number or frequency of transfers between states occurring in the historical data. Based on these estimates, the number of occurrences of neighbouring sub-sequences in the actual data is counted and normalized to a probability value, which represents the likelihood of transferring from one state to another, thus estimating the transfer probability between neighbouring sub-intervals (<xref ref-type="disp-formula" rid="eqn-2">Eq. (2)</xref>).
<disp-formula id="eqn-2"><label>(2)</label><alternatives><graphic mimetype="image" mime-subtype="tif" xlink:href="eqn-2.tif"/><tex-math id="tex-eqn-2"><![CDATA[\begin{equation}p(i,j)=\frac{count(i,j)}{\sum _{k=1}^{N}count(i,j)}\end{equation}]]></tex-math><mml:math id="mml-eqn-2" display="block"></mml:math></alternatives></disp-formula>where P(i,j) denotes the probability of transferring state i to state j in the data; count(i,j) denotes the frequency or number of transfers from state i to state j, which can be obtained by updating the number of (i,j) in real time on the transfer count matrix C initialized with N &#x002A; N (N is the number of states); similarly, count(i,k) denotes the number of transfers from each state i to the other states, denoting the the total number of transfers from state i to any state; the transfer probability P(i,j) can be obtained by dividing the number of transfers in the specified state interval count(i,j) by the total number of transfers from the specified state to any state.</p>
<p>The third step is to construct the Markov transfer field M (<xref ref-type="disp-formula" rid="eqn-3">Eq. (3)</xref>), which achieves the purpose of representing the spatial distribution of transfer probabilities by arranging each transfer probability in the Markov transfer matrix W along the time order. Finally, the matrix elements are mapped to 2D matrix pixel values, and the transformed 2D image is obtained by displaying the transfer probabilities between different states and visualizing the transfer patterns and correlations in the data (<?A3B2 "fig5",5,"anchor"?><xref ref-type="fig" rid="fig-5">Fig. 5</xref>).</p>
<fig id="fig-5">
<label>Figure 5</label>
<caption>
<title>2D image after MTF conversion</title>
</caption>
<graphic mimetype="image" mime-subtype="tif" xlink:href="CMC_51685-fig-5.tif"/>
</fig>
<p><disp-formula id="eqn-3"><label>(3)</label><alternatives><graphic mimetype="image" mime-subtype="tif" xlink:href="eqn-3.tif"/><tex-math id="tex-eqn-3"><![CDATA[\begin{equation}\mathrm{M}=\left[\begin{array}{ccc} \mathrm{w}_{\mathrm{ij}}|\mathrm{x}_{1}\in \mathrm{p}_{\mathrm{i}},\mathrm{x}_{1}\in \mathrm{p}_{\mathrm{j}} & \cdots & \mathrm{w}_{\mathrm{ij}}|\mathrm{x}_{1}\in \mathrm{p}_{\mathrm{i}},\mathrm{x}_{\mathrm{N}}\in \mathrm{p}_{\mathrm{j}}\\ \vdots & \ddots & \vdots \\ \mathrm{w}_{\mathrm{ij}}|\mathrm{x}_{\mathrm{N}}\in \mathrm{p}_{\mathrm{i}},\mathrm{x}_{1}\in \mathrm{p}_{\mathrm{j}} & \cdots & \mathrm{w}_{\mathrm{ij}}|\mathrm{x}_{\mathrm{N}}\in \mathrm{p}_{\mathrm{i}},\mathrm{x}_{\mathrm{N}}\in \mathrm{p}_{\mathrm{j}} \end{array}\right]\end{equation}]]></tex-math><mml:math id="mml-eqn-3" display="block"></mml:math></alternatives></disp-formula></p>


</sec>
<sec id="s3_2">
<label>3.2</label>
<title>Unsharp Masking [<xref ref-type="bibr" rid="ref-26">26</xref>]-for Image Feature Processing</title>
<p>The Unsharp Masking method is an effective image sharpening method, belonging to the second step in the constructed intrusion detection framework for image feature processing, which serves to sharpen the image edge details by enhancing the high-frequency details of the image, and strengthens the deep-level feature expression and learning. It mainly consists of three steps: constructing a blurred image, generating an image with high-frequency details, and enhancing image details (<?A3B2 "fig6",5,"anchor"?><xref ref-type="fig" rid="fig-6">Fig. 6</xref>).</p>
<fig id="fig-6">
<label>Figure 6</label>
<caption>
<title>Unsharp Masking schematic diagram</title>
</caption>
<graphic mimetype="image" mime-subtype="tif" xlink:href="CMC_51685-fig-6.tif"/>
</fig>
<p>Specifically, the original image x(n,m) (n,m represents the pixel coordinates of the image) is first filtered out the high-frequency details by a low-pass filter (e.g., Gaussian filter) to generate a blurred image that does not contain the high-frequency details; then the original image is subtracted from the blurred image to generate the high-frequency detail image z(n,m); and finally the original image is added to the high-frequency detail image by the enhancement factor &#x03BB; to get the output image y(n,m) (<xref ref-type="disp-formula" rid="eqn-4">Eq. (4)</xref>), which is enhanced with details and sharpened with edges. Finally, the original image is added to the high-frequency detail image by the enhancement factor &#x03BB; to obtain the output image y(n,m) after detail enhancement and edge sharpening (<xref ref-type="disp-formula" rid="eqn-4">Eq. (4)</xref>).
<disp-formula id="eqn-4"><label>(4)</label><alternatives><graphic mimetype="image" mime-subtype="tif" xlink:href="eqn-4.tif"/><tex-math id="tex-eqn-4"><![CDATA[\begin{equation}\mathrm{y}(\mathrm{n},\mathrm{m})=\mathrm{x}(\mathrm{n},\mathrm{m})+\lambda \mathrm{z}(\mathrm{n},\mathrm{m})\end{equation}]]></tex-math><mml:math id="mml-eqn-4" display="block"></mml:math></alternatives></disp-formula></p>

<p>Meanwhile, in the traditional USM algorithm, z(n,m) can be generally obtained by <xref ref-type="disp-formula" rid="eqn-5">Eq. (5)</xref>:
<disp-formula id="eqn-5"><label>(5)</label><alternatives><graphic mimetype="image" mime-subtype="tif" xlink:href="eqn-5.tif"/><tex-math id="tex-eqn-5"><![CDATA[\begin{equation}\mathrm{z}(\mathrm{n},\mathrm{m})=4\mathrm{x}(\mathrm{n},\mathrm{m})-\mathrm{x}(\mathrm{n}-1,\mathrm{m})-\mathrm{x}(\mathrm{n}+1,\mathrm{m})-\mathrm{x}(\mathrm{n},\mathrm{m}-1)-\mathrm{x}(\mathrm{n},\mathrm{m}+1)\end{equation}]]></tex-math><mml:math id="mml-eqn-5" display="block"></mml:math></alternatives></disp-formula></p>

<p>The 2D image converted by the MTF method can be filtered by Unsharp Masking to obtain a high-quality image with sharpened edge details (<?A3B2 "fig7",5,"anchor"?><xref ref-type="fig" rid="fig-7">Fig. 7</xref>), which is convenient for the next step of the image classification model to carry out deep feature learning and achieve high-precision anomalous traffic detection and classification.</p>
<fig id="fig-7">
<label>Figure 7</label>
<caption>
<title>2D image after Unsharp Masking</title>
</caption>
<graphic mimetype="image" mime-subtype="tif" xlink:href="CMC_51685-fig-7.tif"/>
</fig>
</sec>
<sec id="s3_3">
<label>3.3</label>
<title>Soft Voting Integration&#x2014;for Image Detection Classification</title>
<p>When using a single image classification model, the classification accuracy and effectiveness may be far inferior to an integrated model built from multiple baseline models, even though the parameters are tuned appropriately. In particular, soft-voting integration methods make decisions by weighted averaging or voting the predictions of multiple models: for a multi-category classification problem, the probabilities of each model on each category are weighted averaged or weighted summed to obtain the final category prediction. It is usually possible to improve the performance of the integrated models, make full use of the advantages of each model, reduce the risk of overfitting, and give higher weights to the predictions with higher confidence, thus improving the overall accuracy and robustness. Therefore, in this paper, we select three baseline image classification models with large differences, MobileNet, VGGNet and ResNet, and integrate them using a soft-voting method to form a final integrated model, AVR Model, belongs to the third step in the constructed intrusion detection framework for image detection classification, to improve the detection accuracy.</p>
<sec id="s3_3_1">
<label>3.3.1</label>
<title>Three Types of Baseline Models&#x2014;MobileNet, VGGNet and ResNet</title>
<p>VGGNet was proposed by Simonyan et al. in 2014 [<xref ref-type="bibr" rid="ref-27">27</xref>], which consists of sixteen convolutional layers and three fully-connected layers with a pooling layer between every two convolutional layers; multiple small 3 &#x002A; 3 convolutional kernels are also stacked to increase the depth of the network to obtain deeper features, and its main feature is that the structure is simple and clear and easy to build; ResNet was proposed by <!--Q1: The author names in the text citations has been changed to match with the reference list. Kindly verify.-->Shafiq et al. proposed in 2015 [<xref ref-type="bibr" rid="ref-28">28</xref>], which introduces residual connections to skip the multilayer structure in the network to mitigate the phenomenon of gradient vanishing, each residual block has multiple convolutional and normalisation layers and is connected by constant mapping, the main feature is that the residual connections are used to effectively mitigate the phenomenon of gradient vanishing.MobileNet belongs to a kind of lightweight model, which was proposed by Google in 2017 of [<xref ref-type="bibr" rid="ref-29">29</xref>], MobileNet replaces the standard convolution in VGGNet with depth-separable convolution, and adds a point-by-point convolution layer using ReLU activation function behind some of the layers, the main feature is to reduce the model size and computation as much as possible while maintaining higher accuracy, and with depth-separable convolution as the core feature, it achieves a good performance in the design of lightweight models [<xref ref-type="bibr" rid="ref-3">3</xref>]. All the above three types of baseline models have achieved good performance in the field of image classification, and their respective characteristics are different and differ. Therefore, in this paper, we adjust to the appropriate model parameters to integrate them with soft voting.</p>
</sec>
<sec id="s3_3_2">
<label>3.3.2</label>
<title>Soft Voting Integration Model&#x2014;AVR Model</title>
<p>AVR Model improves detection accuracy by integrating three classes of baseline models MobileNet, VGGNet and ResNet. Using the soft-voting integration method, the classification results of the three models are weighted and combined to finally form the most credible and unified classification results (Algorithm 1). The integration process can be represented by <xref ref-type="disp-formula" rid="eqn-6">Eq. (6)</xref>:</p>
<statement id="st1">
<label>Algorithm 1 </label>
<title>Soft Voting Integration of VGGNet, MobileNet, and ResNet to Form the AVR Model</title>
<p><bold>Require:</bold></p>
<p>1:List of predictions from three models: predictions_mobile_net, predictions_vgg_net, predictions_res_net</p>
<p>2:List of weights for the three models: weights, ensuring the sum of weights is 1</p>
<p><bold>Procedure:</bold></p>
<p>3:soft_voting_intergration(predictions_mobile_net,predictions_vgg_net,predictions_res_net, weights)</p>
<p><bold>Ensure:</bold></p>
<p>4:final_predictions contains the weighted combination of the predictions from the three models</p>
<p><bold>Begin:</bold></p>
<p>5:&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;final_predictions&#x2002;&#x003D; []</p>
<p>6:&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;for i&#x2002;in range(len(predictions_mobile_net)):</p>
<p>7:&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;# Weighted combination of the predictions from the three models</p>
<p>8:&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;final_prediction&#x2002;&#x003D; (weights [0] &#x002A; predictions_mobile_net[i] &#x002B;</p>
<p>9:&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;weights [1] &#x002A; predictions_vgg_net[i] &#x002B;</p>
<p>10:&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;weights [2] &#x002A; predictions_res_net[i])/sum(weights)</p>
<p>11:&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;final_predictions.append(final_prediction)</p>
<p>12:&#x2002;&#x2002;&#x2002;&#x2002;&#x2002;return final_predictions</p>
<p><bold>End procedure</bold></p>
</statement>
<p><disp-formula id="eqn-6"><label>(6)</label><alternatives><graphic mimetype="image" mime-subtype="tif" xlink:href="eqn-6.tif"/><tex-math id="tex-eqn-6"><![CDATA[\begin{equation}Final_{Pred}=SV(P_{MobileNet},P_{VGGNet},P_{ResNet}\end{equation}]]></tex-math><mml:math id="mml-eqn-6" display="block"></mml:math></alternatives></disp-formula>where SV represents the soft-voting integrated prediction function of the three component models MobileNet, VGGNet &#x0026; ResNet. AVR Model architecture is shown in <?A3B2 "fig8",5,"anchor"?><xref ref-type="fig" rid="fig-8">Fig. 8</xref>.</p>
<fig id="fig-8">
<label>Figure 8</label>
<caption>
<title>AVR model framework structure diagram</title>
</caption>
<graphic mimetype="image" mime-subtype="tif" xlink:href="CMC_51685-fig-8.tif"/>
</fig>
</sec>
</sec>
</sec>
<sec id="s4">
<label>4</label>
<title>Results and Discussion</title>
<p>The focus of this chapter is to describe the conditions, details and process of the experimental implementation in order to confirm the effectiveness of the methods involved with the construction of the intrusion detection framework. Based on various evaluation metrics, the performance of the methodological models is evaluated in all aspects to illustrate the limitations and advantages of the models to provide a feasible and high performance approach for the field of intrusion detection.</p>
<sec id="s4_1">
<label>4.1</label>
<title>Introduction to the Data Set</title>
<p>Considering the necessity of comparing with other related work in the field of intrusion detection and the applicability of the application scenario as IoT, this paper selects two publicly available datasets: the dataset CICIDS2018, which is widely used by researchers, to facilitate comparative experiments with other models; and the dataset N_BaIoT, which contains data on networking of smart devices in the Internet of Things (IoT), in order to validate the fit with IoT environments.</p>
<sec id="s4_1_1">
<label>4.1.1</label>
<title>CICIDS2018</title>
<p>CICIDS2018 dataset was collected by the Canadian Institute for Cybersecurity Research in 2018 and contains seven types of attack scenarios: brute force, heartbleed leaks, botnets, DoS, DDoS, web attacks, and internal penetration, collected from five departments, 420 machines, and 30 servers using the CICFlowMeters-V3 traffic capture software. Compared to the NSL-KDD, KDDCUP99 dataset, the temporal dimension is more novel and contains the latest cyberattack diversity and capacity. However, CICIDS2018 contains 16,232,943 data, including 59,721 null data, and there are also incomplete and repetitive data, the massive data will increase the training model overhead, and the meaningless data will reduce the model efficiency. Therefore, data preprocessing is carried out, data cleaning is performed, null data, error data, incomplete data and duplicate data are deleted, and three major types of attack data and one type of normal data are extracted according to the difficulty of each type of attack in the original data, forming a new training set and test set (<?A3B2 "tbl2",5,"anchor"?><xref ref-type="table" rid="table-2">Table 2</xref>).</p>
<table-wrap id="table-2">
<label>Table 2 </label>
<caption>
<title>Data distribution of the CICIDS2018 train and test sets</title>
</caption>
<alternatives>
<graphic mimetype="image" mime-subtype="tif" xlink:href="table-2.tif"/>
<table>
<colgroup>
<col/>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<thead>
<tr>
<th>Type of attack</th>
<th>Train set</th>
<th>Number</th>
<th>Test set</th>
<th>Number</th>
</tr>
</thead>
<tbody>
<tr>
<td>Normal</td>
<td>Benign</td>
<td>16899</td>
<td>Benign</td>
<td>4225</td>
</tr>
<tr>
<td>Botnet</td>
<td>Botnet attack</td>
<td>16144</td>
<td>Botnet attack</td>
<td>4036</td>
</tr>
<tr>
<td>DDoS</td>
<td>DDoS-LOIC-HTTP<break/>DDOS-HOIC</td>
<td>17024</td>
<td>DDoS-LOIC-HTTP<break/>DDOS-HOIC,DDOS-LOIC-UDP</td>
<td>4256</td>
</tr>
<tr>
<td>Bruteforce</td>
<td>FTP-Bruteforce</td>
<td>16840</td>
<td>FTP-Bruteforce, SSH-Bruteforce</td>
<td>4210</td>
</tr>
<tr>
<td>Total</td>
<td>5</td>
<td>66907</td>
<td>7</td>
<td>16727</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>CICIDS2018 contains a total of 83 features and 1 tag class, deleting the &#x201C;Timestamp&#x201D; feature because Timestamp records the time of the attack, which has no practical significance and reference value for the detection of network attacks in all-weather hours; deleting the &#x201C;Flow ID&#x201D;, &#x201C;Src IP&#x201D;, &#x201C;Src Port&#x201D;, and &#x201C;Dst IP&#x201D; because these four features only appear in the flow of one day, and most of the flow data does not contain these features; using the remaining 78 features for the training of the intrusion detection model, as shown in <?A3B2 "tbl3",5,"anchor"?><xref ref-type="table" rid="table-3">Table 3</xref>.</p>
<table-wrap id="table-3">
<label>Table 3</label>
<caption>
<title>Featured description of CICIDS2018</title>
</caption>
<alternatives>
<graphic mimetype="image" mime-subtype="tif" xlink:href="table-3.tif"/>
<table>
<colgroup>
<col/>
<col/>
</colgroup>
<thead>
<tr>
<th>Feature</th>
<th>Feature information/attributes</th>
</tr>
</thead>
<tbody>
<tr>
<td>1&#x2013;4</td>
<td>Network connection</td>
</tr>
<tr>
<td>5&#x2013;15</td>
<td>Network packet</td>
</tr>
<tr>
<td>16&#x2013;21</td>
<td>Network flow</td>
</tr>
<tr>
<td>22&#x2013;44</td>
<td>Statistics of network traffic</td>
</tr>
<tr>
<td>45&#x2013;62</td>
<td>Content-related traffic features</td>
</tr>
<tr>
<td>63&#x2013;66</td>
<td>Network sub-traffic features</td>
</tr>
<tr>
<td>67&#x2013;78</td>
<td>Generic flow features</td>
</tr>
<tr>
<td>78&#x2013;79</td>
<td>Labels</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
</sec>
<sec id="s4_1_2">
<label>4.1.2</label>
<title>N_BaIoT</title>
<p>N_BaIoT dataset contains malicious attack traffic collected from nine IoT devices involving two types of botnet attacks, Mirai and BASHLITE, which can be subdivided into 10 categories of attacks, and are specifically designed to launch botnet attacks against IoT environments. N_BaIoT contains a total of 7062606 instance data, and in order to improve the model training efficiency and reduce unnecessary arithmetic consumption, the training set and test set are divided according to <?A3B2 "tbl4",5,"anchor"?><xref ref-type="table" rid="table-4">Table 4</xref>. In addition, its 115 features are appropriately filtered and cleaned for input into the intrusion detection framework.</p>
<table-wrap id="table-4">
<label>Table 4</label>
<caption>
<title>Data distribution of the N_BaIoT train and test sets</title>
</caption>
<alternatives>
<graphic mimetype="image" mime-subtype="tif" xlink:href="table-4.tif"/>
<table>
<colgroup>
<col/>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<thead>
<tr>
<th>Class</th>
<th>Train set</th>
<th>Number</th>
<th>Test set</th>
<th>Number</th>
</tr>
</thead>
<tbody>
<tr>
<td>Normal</td>
<td>Normal</td>
<td>34806</td>
<td>Normal</td>
<td>14917</td>
</tr>
<tr>
<td>BASHLITE attack</td>
<td>Scan (BASH), Junk COMBO, UDP (BASH)</td>
<td>6869</td>
<td>Scan (BASH), Junk COMBO, UDP (BASH), TCP flooding</td>
<td>5778</td>
</tr>
<tr>
<td>Mirai attack</td>
<td>Ack, Syn, UDPplain</td>
<td>6051</td>
<td>Ack, Syn, UDPplain, Scan(Mirai), UDP(Mirai)</td>
<td>5663</td>
</tr>
<tr>
<td>Total</td>
<td>8</td>
<td>47726</td>
<td>11</td>
<td>26358</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
</sec>
</sec>
<sec id="s4_2">
<label>4.2</label>
<title>Evaluation of Indicators</title>
<p>In order to facilitate comparison and validation with other related work in the field of intrusion detection, this paper selects four common types of evaluation metrics: accuracy, precision, recall and F1-Score, where accuracy is used to measure the proportion of samples correctly predicted by the model, precision is used to measure the reliability of the model in making positive class predictions, recall is used to measure the ability of the model to predict positive samples, and F1-Score is a combined consideration of precision and recall, and is the reconciled average of the two. Recall are considered together and are the reconciled mean of the two, which is used to measure the balanced performance of the model:
<disp-formula id="eqn-7"><label>(7)</label><alternatives><graphic mimetype="image" mime-subtype="tif" xlink:href="eqn-7.tif"/><tex-math id="tex-eqn-7"><![CDATA[\begin{equation}Accuracy=\frac{TP+TN}{FP+FN+TP+TN}\end{equation}]]></tex-math><mml:math id="mml-eqn-7" display="block"></mml:math></alternatives></disp-formula>
<disp-formula id="eqn-8"><label>(8)</label><alternatives><graphic mimetype="image" mime-subtype="tif" xlink:href="eqn-8.tif"/><tex-math id="tex-eqn-8"><![CDATA[\begin{equation}Precision=\frac{TP}{FP+TP}\end{equation}]]></tex-math><mml:math id="mml-eqn-8" display="block"></mml:math></alternatives></disp-formula>
<disp-formula id="eqn-9"><label>(9)</label><alternatives><graphic mimetype="image" mime-subtype="tif" xlink:href="eqn-9.tif"/><tex-math id="tex-eqn-9"><![CDATA[\begin{equation}Recall=\frac{TP}{FN+TP}\end{equation}]]></tex-math><mml:math id="mml-eqn-9" display="block"></mml:math></alternatives></disp-formula>
<disp-formula id="eqn-10"><label>(10)</label><alternatives><graphic mimetype="image" mime-subtype="tif" xlink:href="eqn-10.tif"/><tex-math id="tex-eqn-10"><![CDATA[\begin{equation}F_{1}-score=2\times \frac{Precision\times Recall}{Precision+Recall}\end{equation}]]></tex-math><mml:math id="mml-eqn-10" display="block"></mml:math></alternatives></disp-formula></p>

<p>The meanings of the sub-indicators TP, TN, FP and FN are shown in <?A3B2 "tbl5",5,"anchor"?><xref ref-type="table" rid="table-5">Table 5</xref>:</p>
<table-wrap id="table-5">
<label>Table 5</label>
<caption>
<title>Meaning of TP, TN, FP, FN</title>
</caption>
<alternatives>
<graphic mimetype="image" mime-subtype="tif" xlink:href="table-5.tif"/>
<table>
<colgroup>
<col/>
<col/>
<col/>
</colgroup>
<thead>
<tr>
<th>Actual\prediction</th>
<th>Positive</th>
<th>Negative</th>
</tr>
</thead>
<tbody>
<tr>
<td>Positive</td>
<td>TP</td>
<td>FN</td>
</tr>
<tr>
<td>Negative</td>
<td>FP</td>
<td>TN</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
</sec>
<sec id="s4_3">
<label>4.3</label>
<title>Experimental Implementation</title>
<p>To validate the effectiveness of the proposed method and the constructed framework in this paper, three types of experiments are mainly conducted on two datasets, CICIDS2018 and N_BaIoT: (1) ablation experiments are conducted on the MTF used for data type conversion and compared with other type conversion methods to validate the effectiveness of the MTF on the conversion of one-dimensional data to two-dimensional images; (2) ablation experiments on AVR Model, a soft-voting integration model for image detection and classification, and compare its detection performance with individual baseline models VGGNet, ResNet and MobileNet on task scenarios to validate the utility of the integration approach for image classification; (3) comparative evaluation experiments on MUS Model, an entire intrusion detection framework, compared with SVM, DT, RNN, CNN four classes of machines with deep learning baseline models to illustrate the value of the work done.</p>
<sec id="s4_3_1">
<label>4.3.1</label>
<title>Evaluation of MTF Methods for Data Type Conversion</title>
<p>Since the images generated in this paper are mainly used for the detection of the image classification module, no metrics specifically for assessing image quality are used; instead, different data conversion methods are combined and compared with the baseline image classification model, CNN, so as to illustrate the effectiveness of the MTF method in the whole intrusion detection framework using classification assessment metrics. Firstly, this paper selects unprocessed one-dimensional data as the input source and compares the detection performance of MTF on CNN to illustrate the necessity and importance of data type conversion; meanwhile, classical data type conversion methods such as GAF, STFT and recursive map are set as the control group to illustrate that it is more effective and practical to adopt the MTF method in the intrusion detection framework constructed in this paper.</p>
<p>As can be seen from <?A3B2 "fig9",5,"anchor"?><xref ref-type="fig" rid="fig-9">Fig. 9</xref>, the MTF method in the constructed framework achieves higher detection accuracy on both the CICIDS2018 and N_BaIoT datasets compared to the control group, which can be explained in two ways: firstly, compared to the one-dimensional data processing methods that do not use image conversion methods, the STFT, Recurrence Plot, GAF, and MTF methods that convert the one-dimensional network traffic data into 2D images for detection and classification, all of which achieve a high accuracy rate, due to the fact that the conversion of data types can learn deep features, and 2D images are more capable of capturing spatio-temporal features; it facilitates the use of advanced computer vision and image processing techniques to enhance the pattern recognition ability, which leads to effective training and classification, and embodies the superiority of the idea; secondly, in comparison with STFT, Recurrence Plot, GAF and other image transformation methods, the MTF method achieves the best performance on both the CICIDS2018 and N_BaIoT datasets, which is due to the fact that the MTF can extract features at multiple scales, thus capturing patterns and features at different scales in the dataset, which helps to characterise the data in a more comprehensive way and facilitates subsequent detection classification. It is also worth noting that the experimental results show that all the four types of methods outperform the dataset N_BaIoT on the dataset CICIDS2018, indicating that the adopted frameworks are more effective in representing the characteristics of the CICIDS2018 dataset, which is not only applicable to the widely used IoT, but also applicable to different scenarios and attack types.</p>
<fig id="fig-9">
<label>Figure 9</label>
<caption>
<title>Experimental diagram of MTF evaluation</title>
</caption>
<graphic mimetype="image" mime-subtype="tif" xlink:href="CMC_51685-fig-9.tif"/>
</fig>
</sec>
<sec id="s4_3_2">
<label>4.3.2</label>
<title>Evaluation of AVR Model</title>
<p>In order to comprehensively evaluate the effectiveness of the constructed integrated model AVR Model, it is compared with three single baseline models, VGGNet, ResNet and MobileNet, in the classification task of two types of datasets, and the experimental results of the four evaluation metrics are as follows:</p>
<p>As can be seen from <?A3B2 "fig10",5,"anchor"?><xref ref-type="fig" rid="fig-10">Fig. 10</xref>, AVR Model outperforms the single baseline model in all four categories of evaluation metrics on both types of datasets. This is due to the fact that AVR Model has the characteristic of diversity integration, which is able to gather the advantages of the three models and make up for their shortcomings; in addition, it is able to reduce the risk of overfitting, synthesise the feature representations of each baseline model, and reduce the stochasticity. Specifically, AVR Model significantly outperforms all the single baseline models in terms of overall classification accuracy, which indicates that the integrated model is able to combine the advantages of the different models and handle complex classification tasks more efficiently; the precision rate of AVR Model also exhibits high performance, which suggests that there are fewer misclassifications in determining the positive class of samples; and lastly, the significant improvement in the F1 scores further proves that AVR Model is superior in maintaining a balance between precision rate and recall balance of AVR model. Taking the above experimental results together, it can be seen that AVR model outperforms the single baseline model in all the evaluation metrics, proving its effectiveness and efficiency in dealing with complex classification tasks. This is due to its ability to integrate the features of multiple models, thus compensating for the deficiencies of a single model and improving the overall performance.</p>
<fig id="fig-10">
<label>Figure 10</label>
<caption>
<title>Experimental diagram of AVR model evaluation</title>
</caption>
<graphic mimetype="image" mime-subtype="tif" xlink:href="CMC_51685-fig-10.tif"/>
</fig>
</sec>
<sec id="s4_3_3">
<label>4.3.3</label>
<title>Evaluation of MUS Model</title>
<p>The above two types of ablation experiments illustrate the effectiveness of the modules in the intrusion detection framework, however, the role of the independent modules does not indicate the performance of the overall framework. Therefore, in order to evaluate the superiority of the intrusion detection framework MUS in the field of IoT security, comparative experiments with classical machine learning models SVM, DT and deep learning models RNN, CNN are conducted on two types of datasets, CICIDS2018 and N_BaIoT, and evaluated with four types of metrics.</p>
<p>As can be seen from <?A3B2 "fig11",5,"anchor"?><xref ref-type="fig" rid="fig-11">Fig. 11</xref>, the constructed MUS intrusion detection framework achieves the highest detection accuracy on the CICIDS2018 dataset, indicating that MUS can identify intrusions more accurately in complex network traffic data; MUS likewise performs best on the N_BaIoT dataset, which contains a large amount of data from IoT devices,. It further shows that MUS has strong detection capability in IoT environment. Taken together, the above experimental results show that the MUS framework demonstrates better performance than traditional machine learning models and deep learning models on both types of datasets, this is due to the fact that the MUS framework contains three modules of data conversion, image processing and detection and classification, which are able to convert one-dimensional data into two-dimensional images, mine deep-seated features with the help of advanced computer vision and image processing techniques, and use the soft-voting integration model AVR to combine the advantages of the three types of baseline models for accurate detection, which further proves the superiority of the MUS framework in the field of IoT security, and its efficient detection capability can help better identify and defend against a variety of cyber-attacks.</p>
<fig id="fig-11">
<label>Figure 11</label>
<caption>
<title>Experimental diagram of MUS model evaluation</title>
</caption>
<graphic mimetype="image" mime-subtype="tif" xlink:href="CMC_51685-fig-11.tif"/>
</fig>
</sec>
<sec id="s4_3_4">
<label>4.3.4</label>
<title>Tests of Model Variability</title>
<p>The Friedman test is a non-parametric test to determine whether multiple algorithms have the same performance. The Nemenyi follow-up test, on the other hand, further determines whether the difference between the mean ordinal values of two algorithms exceeds the critical value domain on the basis of the Friedman test to identify significant differences in algorithm performance. In order to compare whether there is any difference between the intrusion detection framework MUS constructed in this paper and the baseline machine learning and deep learning models, the experiments implemented in <xref ref-type="sec" rid="s4_3">Section 4.3</xref> are used as the research object to launch the model difference test.</p>
<p>The original hypothesis of the Friedman test is that the overall median is equal for all samples, and the alternative hypothesis is that the overall median is different for at least one sample. In performing the Friedman test, the data in each sample are first ranked, and then the rank order of each observation is calculated; and then the ranks in each sample are summed to obtain the rank sum of the sample. Finally, a statistical test is performed using the computed rank sum, and the distribution of the test statistic approximates a chi-square distribution with k &#x2212; 1 degrees of freedom, where k is the number of samples, N is the number of datasets, and r<sub>i</sub> denotes the average ordinal value of the ith algorithm.
<disp-formula id="eqn-11"><label>(11)</label><alternatives><graphic mimetype="image" mime-subtype="tif" xlink:href="eqn-11.tif"/><tex-math id="tex-eqn-11"><![CDATA[\begin{equation}\uptau _{{\mathrm{x}^{2}}}=\frac{12\mathrm{N}}{\mathrm{k}(\mathrm{k}+1)}(\sum\nolimits _{\mathrm{i}=1}^{\mathrm{k}}\mathrm{r}_{\mathrm{i}}^{2}-\frac{\mathrm{k}(\mathrm{k}+1)^{2}}{4})\end{equation}]]></tex-math><mml:math id="mml-eqn-11" display="block"></mml:math></alternatives></disp-formula></p>

<p>The F-distribution <inline-formula id="ieqn-1"><alternatives><inline-graphic xlink:href="ieqn-1.tif"/><tex-math id="tex-ieqn-1"><![CDATA[$\uptau _{\mathrm{F}}$]]></tex-math><mml:math id="mml-ieqn-1"></mml:math></alternatives></inline-formula> obeying degrees of freedom k &#x2212; 1 and (k &#x2212; 1) (N &#x2212; 1) can be derived from <inline-formula id="ieqn-2"><alternatives><inline-graphic xlink:href="ieqn-2.tif"/><tex-math id="tex-ieqn-2"><![CDATA[$\uptau _{{\mathrm{x}^{2}}}$]]></tex-math><mml:math id="mml-ieqn-2"></mml:math></alternatives></inline-formula>.
<disp-formula id="eqn-12"><label>(12)</label><alternatives><graphic mimetype="image" mime-subtype="tif" xlink:href="eqn-12.tif"/><tex-math id="tex-eqn-12"><![CDATA[\begin{equation}\tau _{F}=\frac{(N-1)\tau _{{x^{2}}}}{N(k-1)-\tau _{{x^{2}}}}\end{equation}]]></tex-math><mml:math id="mml-eqn-12" display="block"></mml:math></alternatives></disp-formula></p>

<p>As a result of these calculations, the Friedman test rejected the original hypothesis, indicating that at least one of the models differed significantly in performance on at least one of the metrics. Therefore a Nemenyi follow-up test was conducted.The Nemenyi test calculates the critical value domain for the difference in mean ordinal values:</p>
<p><disp-formula id="eqn-13"><label>(13)</label><alternatives><graphic mimetype="image" mime-subtype="tif" xlink:href="eqn-13.tif"/><tex-math id="tex-eqn-13"><![CDATA[\begin{equation}CD=q_{\alpha }\sqrt{\frac{k(k+1)}{6N}}\end{equation}]]></tex-math><mml:math id="mml-eqn-13" display="block"></mml:math></alternatives></disp-formula>where is the fixed critical value derived from checking the table. In this paper, the CD is 1.9268, and after control, it is found that MUS is significantly different from SVM, DT, and RNN, while it is not significantly different from CNN (<?A3B2 "fig12",5,"anchor"?><xref ref-type="fig" rid="fig-12">Fig. 12</xref>)</p>
<fig id="fig-12">
<label>Figure 12</label>
<caption>
<title>Critical difference (CD) diagram</title>
</caption>
<graphic mimetype="image" mime-subtype="tif" xlink:href="CMC_51685-fig-12.tif"/>
</fig>
<p>This is due to the fact that the three baseline models of the soft voting integration model in MUS: VGGNet, ResNet and MobileNet all belong to the classical convolutional model and therefore do not differ much from CNN, but in terms of the four types of performance metrics, have a significant enhancement, which illustrates the validity and practicability of the constructed framework MUS.</p>
</sec>
</sec>
<sec id="s4_4">
<label>4.4</label>
<title>Discussion</title>
<p>From the four types of experimental parts mentioned above, it can be concluded that each module of the constructed part plays a corresponding role and contributes to the effectiveness of the overall framework in IoT intrusion detection. Among them, the data type conversion module consisting of the MTF method for converting 1D network traffic data into 2D images has higher evaluation indexes in all four categories than the direct processing of 1D data and the baseline image classification method, which illustrates the necessity of data type conversion and the applicability of the adopted MTF method; the detection and classification model AVR, which is obtained by integrating the three image classification baseline models of VGGNet, ResNet, and Mobile Net by the soft polling The detection and classification model AVR Model obtained from the soft-vote integration of VGGNet, ResNet, and Mobile Net has higher detection accuracy compared with the above three baseline models, which illustrates the effectiveness of the soft-vote integration method; finally, the IoT intrusion detection framework MUS constructed by the research institute has the best performance in the four types of evaluation indexes compared with commonly used machine learning and deep learning models, which further illustrates the excellent performance of the constructed framework AVR model performance; the experimental performance on two types of datasets, CICIDS2018 and N_BaIoT, fully proves that MUS is not only suitable for IoT intrusion detection environments, but also for different attack types and network environments.</p>
<p>However, the experimental setup is limited in some aspects and needs to be further improved. First, in terms of dataset selection bias, the division of training and testing sets in CICIDS2018 and N_BaIoT is random, which cannot cover each traffic data of each attack type, and there exists one-sidedness; in addition, although the dataset used in the experiments has covered the real network environments and the specific IoT environments, it is not possible for them to cover all possible intrusion scenarios and network environments, and the model&#x2019;s ability to generalise in unknown environment, the generalisation ability of the model in unknown environments needs to be further verified. Second, the four categories of indicators used in the experimental evaluation are commonly used in the field of intrusion detection, which can illustrate the high-performance performance of the constructed framework on the IoT intrusion detection task scenarios; however, it gives the same weight to the prediction performance of all categories, which does not take into account the requirements of practical applications, and needs to be explored and improved in the next step.</p>
</sec>
</sec>
<sec id="s5">
<label>5</label>
<title>Conclusion and Outlook</title>
<p>In order to fully improve the performance of the IoT intrusion detection model, considering the superiority of deep learning models in learning and training high-dimensional data, this paper constructs an IoT intrusion detection framework, MUS Model, based on MTF, Unsharp Masking, and soft-voting integration models, and conducts three types of experiments on two datasets to prove that each module of the constructed framework MUS is necessary and all contribute to the final performance improvement, and that the overall framework is applicable not only to IoT intrusion detection environments, but also to different attack types and network environments. This fully demonstrates the following conclusions: (1) after converting 1D network traffic data into 2D images, it is effective to detect and classify them using advanced computer vision techniques, which shows that the data type conversion can fully leverage the visual feature extraction techniques to improve the detection performance to a certain extent; (2) processing the converted data images is necessary to facilitate learning to extract the deeper features and optimise the detection performance; (3) the soft-voting integration method can combine the advantages of different baseline models and reduce the risk of overfitting, which provides a reference for the subsequent improvement of intrusion detection performance under different task scenarios.</p>
<p>However, this paper only focuses on the enhancement of intrusion detection performance in the IoT domain without considering the resource constraints. In the future IoT security domain, with the explosive growth of the number of devices and the increasing complexity of the network environment, the intrusion detection system not only needs to have high-precision detection capability to accurately identify and defend against a variety of threats, but also must have fast inference speed and lightweight model design to adapt to resource-constrained IoT devices and to ensure real-time security requirements. To achieve this goal, the following methods are proposed for refinement: model compression and pruning, knowledge refinement, quantification, hardware-specific optimisation, joint-learning distributed training, etc.,; through the combined use of the above methods, both the performance and efficiency of the IoT intrusion detection model can be improved, and its feasibility and practicability can be ensured in resource-constrained environments, so that the growing IoT ecosystem can be better protected from security threats.</p>
</sec>
</body>
<back>
<ack>
<p>The authors would like to thank the support and help from the People&#x2019;s Armed Police Force of China Engineering University, College of Information Engineering subject group, which funded this work under the All-Army Military Theory Research Project, Armed Police Force Military Theory Research Project.</p>
</ack>
<fn-group>
<fn fn-type="other">
<p><bold>Funding Statement:</bold> The authors would like to thank the support and help from the People&#x2019;s Armed Police Force of China Engineering University, College of Information Engineering subject group, which funded this work under the All-Army Military Theory Research Project, Armed Police Force Military Theory Research Project (WJJY22JL0498).</p>
</fn>
<fn fn-type="other">
<p><bold>Author Contributions:</bold> The authors confirm contribution to the paper as follows: conceptualization, methodology, Yu Yan; formal analysis, investigation, Yu Yan, Shen Fang; writing&#x2014;original draft preparation, Yu Yan, Minna Gao; writing&#x2014;review and editing, Yu Yan, Yu Yang; supervision, resources, funding acquisition, Yu Yang. All authors reviewed the results and approved the final version of the manuscript.</p>
</fn>
<fn fn-type="other">
<p><bold>Availability of Data and Materials:</bold> Data available on request from the authors. &#x201C;The data that support the findings of this study are available from the corresponding author, [Yu Yang], upon reasonable request.</p>
</fn>
<fn fn-type="conflict">
<p><bold>Conflicts of Interest:</bold> The authors declare that they have no conflicts of interest to report regarding the present study.</p>
</fn>
</fn-group>
<ref-list content-type="authoryear">
<title>References</title>
<ref id="ref-1"><label>1</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names> <surname>Leo</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Medioni</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Trivedi</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Kanade</surname></string-name>, and <string-name><given-names>G.</given-names> <surname>Farinella</surname></string-name></person-group>, &#x201C;<article-title>Computer vision for assistive technologies</article-title>,&#x201D; <source>Comput. Vis. Image Underst.</source>, vol. <volume>154</volume>, no. <issue>1</issue>, pp. <fpage>1</fpage>&#x2013;<lpage>15</lpage>, <year>Jan. 2017</year>. doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cviu.2016.09.001">10.1016/j.cviu.2016.09.001</ext-link>.</mixed-citation></ref>
<ref id="ref-2"><label>2</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S.</given-names> <surname>Madakam</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Ramaswamy</surname></string-name>, and <string-name><given-names>S.</given-names> <surname>Tripathi</surname></string-name></person-group>, &#x201C;<article-title>Internet of things (IoT): A literature review</article-title>,&#x201D; <source>J. Comput. Commun.</source>, vol. <volume>3</volume>, no. <issue>5</issue>, pp. <fpage>164</fpage>&#x2013;<lpage>173</lpage>, <year>2015</year>. doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.4236/jcc.2015.35021">10.4236/jcc.2015.35021</ext-link>.</mixed-citation></ref>
<ref id="ref-3"><label>3</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>E.</given-names> <surname>Eliando</surname></string-name> and <string-name><given-names>Y.</given-names> <surname>Purnomo</surname></string-name></person-group>, &#x201C;<article-title>LockBit 2.0 ransomware: Analysis of infection, persistence, prevention mechanism</article-title>,&#x201D; <source>CogITo Smart J.</source>, vol. <volume>8</volume>, no. <issue>1</issue>, pp. <fpage>232</fpage>&#x2013;<lpage>243</lpage>, <year>2022</year>. doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.31154/cogito.v8i1.356.232-243">10.31154/cogito.v8i1.356.232-243</ext-link>.</mixed-citation></ref>
<ref id="ref-4"><label>4</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>H.</given-names> <surname>Zahan</surname></string-name>, <string-name><given-names>M. W.</given-names> <surname>Al Azad</surname></string-name>, <string-name><given-names>I.</given-names> <surname>Ali</surname></string-name>, and <string-name><given-names>S.</given-names> <surname>Mastorakis</surname></string-name></person-group>, &#x201C;<article-title>IoT-AD: A framework to detect anomalies among interconnected IoT devices</article-title>,&#x201D; <source>IEEE Internet Things J.</source>, vol. <volume>11</volume>, no. <issue>1</issue>, pp. <fpage>478</fpage>&#x2013;<lpage>489</lpage>, <year>Jun. 2023</year>. doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1109/JIOT.2023.3285714">10.1109/JIOT.2023.3285714</ext-link>.</mixed-citation></ref>
<ref id="ref-5"><label>5</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Y.</given-names> <surname>Khan</surname></string-name>, <string-name><given-names>M. B.</given-names> <surname>Su&#x2019;ud</surname></string-name>, <string-name><given-names>M. M.</given-names> <surname>Alam</surname></string-name>, <string-name><given-names>S. F.</given-names> <surname>Ahmad</surname></string-name>, <string-name><given-names>N. A.</given-names> <surname>Salim</surname></string-name>, and <string-name><given-names>N.</given-names> <surname>Khan</surname></string-name></person-group>, &#x201C;<article-title>Architectural threats to security and privacy: A challenge for internet of things (IoT) applications</article-title>,&#x201D; <source>Electronics</source>, vol. <volume>12</volume>, no. <issue>1</issue>, pp. <fpage>88</fpage>, <year>Dec. 2022</year>. doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3390/electronics12010088">10.3390/electronics12010088</ext-link>.</mixed-citation></ref>
<ref id="ref-6"><label>6</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J.</given-names> <surname>Li</surname></string-name>, <string-name><given-names>X.</given-names> <surname>Qi</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>He</surname></string-name>, and <string-name><given-names>L.</given-names> <surname>Liu</surname></string-name></person-group>, &#x201C;<article-title>SDN candidate and protection path selection for link failure protection in hybrid SDNs</article-title>,&#x201D; <source>Reliab. Eng. Syst. Saf.</source>, vol. <volume>244</volume>, no. <issue>109893</issue>, <year>Apr. 2024</year>. doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.ress.2023.109893">10.1016/j.ress.2023.109893</ext-link>.</mixed-citation></ref>
<ref id="ref-7"><label>7</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. J.</given-names> <surname>Huang</surname></string-name>, <string-name><given-names>Y. T.</given-names> <surname>Liu</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Yang</surname></string-name>, <string-name><given-names>Y. Q.</given-names> <surname>Zhao</surname></string-name>, and <string-name><given-names>M. R.</given-names> <surname>Zhang</surname></string-name></person-group>, &#x201C;<article-title>Efficient revocable attribute-based encryption with data integrity and key escrow-free</article-title>,&#x201D; <source>Information</source>, vol. <volume>15</volume>, no. <issue>1</issue>, pp. <fpage>32</fpage>, <year>Jan. 2024</year>. doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3390/info15010032">10.3390/info15010032</ext-link>.</mixed-citation></ref>
<ref id="ref-8"><label>8</label><mixed-citation publication-type="conf-proc"><person-group person-group-type="author"><string-name><given-names>S.</given-names> <surname>Ioannidis</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Keromytis</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Bellovin</surname></string-name>, and <string-name><given-names>J.</given-names> <surname>Smith</surname></string-name></person-group>, &#x201C;<article-title>Implementing a distributed firewall</article-title>,&#x201D; in <conf-name>Proc. 7th ACM Conf. Comput. Commun. Secur.</conf-name>, <publisher-loc>Athens, Greece</publisher-loc>, <year>2000</year>, pp. <fpage>190</fpage>&#x2013;<lpage>199</lpage>.</mixed-citation></ref>
<ref id="ref-9"><label>9</label><mixed-citation publication-type="conf-proc"><person-group person-group-type="author"><string-name><given-names>P.</given-names> <surname>Samarati</surname></string-name> and <string-name><given-names>S. C.</given-names> <surname>De Vimercati</surname></string-name></person-group>, &#x201C;<article-title>Access control: Policies, models, and mechanisms</article-title>,&#x201D; in <conf-name>Int. Sch. Found. Secur. Anal. Des.</conf-name>, <publisher-loc>Berlin, Heidelberg</publisher-loc>, <publisher-name>Springer Berlin Heidelberg</publisher-name>, <year>2000</year>, pp. <fpage>137</fpage>&#x2013;<lpage>196</lpage>. doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/3-540-45608-2_3">10.1007/3-540-45608-2_3</ext-link>.</mixed-citation></ref>
<ref id="ref-10"><label>10</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names> <surname>Polenov</surname></string-name>, <string-name><given-names>V.</given-names> <surname>Guzik</surname></string-name>, and <string-name><given-names>V.</given-names> <surname>Lukyanov</surname></string-name></person-group>, &#x201C;<article-title>Using virtualization technology for the user authorization system</article-title>,&#x201D; <source>Softw. Eng. Trends and Tech. Intell. Syst.: Proc. 6th Comput. Sci. On-Line Conf. 2017 (CSOC2017)</source>, vol. <volume>3</volume>, no. <issue>6</issue>, pp. <fpage>192</fpage>&#x2013;<lpage>200</lpage>, <year>Apr. 2017</year>. doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/978-3-319-57141-6_20">10.1007/978-3-319-57141-6_20</ext-link>.</mixed-citation></ref>
<ref id="ref-11"><label>11</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Y.</given-names> <surname>Yan</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Yang</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Shen</surname></string-name>, <string-name><given-names>M. N.</given-names> <surname>Gao</surname></string-name>, and <string-name><given-names>Y. H.</given-names> <surname>Gu</surname></string-name></person-group>, &#x201C;<article-title>GDE model: A variable intrusion detection model for few-shot attack</article-title>,&#x201D; <source>J. King Saud Univ.&#x2014;Comput. Inf. Sci.</source>, vol. <volume>35</volume>, no. <issue>10</issue>, pp. <fpage>101796</fpage>, <year>Dec. 2023</year>. doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.jksuci.2023.101796">10.1016/j.jksuci.2023.101796</ext-link>.</mixed-citation></ref>
<ref id="ref-12"><label>12</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><given-names>J. P.</given-names> <surname>Anderson</surname></string-name></person-group>, <chapter-title>Computer security threat monitoring and surveillance</chapter-title>. in <source>Technical Report</source>. vol. <volume>215</volume>. <publisher-loc>Fort Washington, Pennsylvania</publisher-loc>: <publisher-name>James P Anderson Co</publisher-name>, pp. <fpage>646</fpage>&#x2013;<lpage>4706</lpage>, <year>1980</year>.</mixed-citation></ref>
<ref id="ref-13"><label>13</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>G. E.</given-names> <surname>Hinton</surname></string-name> and <string-name><given-names>R. R.</given-names> <surname>Salakhutdinov</surname></string-name></person-group>, &#x201C;<article-title>Reducing the dimensionality of data with neural networks</article-title>,&#x201D; <source>Science</source>, vol. <volume>313</volume>, no. <issue>5786</issue>, pp. <fpage>504</fpage>&#x2013;<lpage>507</lpage>, <year>Jul. 2006</year>. doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/science.112764">10.1126/science.112764</ext-link>.</mixed-citation></ref>
<ref id="ref-14"><label>14</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. S.</given-names> <surname>Farooq</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Abbas</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Sultan</surname></string-name>, <string-name><given-names>MA.</given-names> <surname>Atta-ur-Rahman</surname></string-name>, <string-name><given-names>MA.</given-names> <surname>Khan</surname></string-name>, and <string-name><given-names>A.</given-names> <surname>Mosavi</surname></string-name></person-group>, &#x201C;<article-title>A fused machine learning approach for intrusion detection system</article-title>,&#x201D; <source>Comput. Mater. Contin.</source>, vol. <volume>74</volume>, no. <issue>2</issue>, pp. <fpage>2607</fpage>&#x2013;<lpage>2623</lpage>, <year>Apr. 2023</year>. doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.32604/cmc.2023.032617">10.32604/cmc.2023.032617</ext-link>.</mixed-citation></ref>
<ref id="ref-15"><label>15</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>E. U. H.</given-names> <surname>Qazi</surname></string-name>, <string-name><given-names>M. H.</given-names> <surname>Faheem</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Zia</surname></string-name></person-group>, &#x201C;<article-title>HDLNIDS: Hybrid deep-learning-based network intrusion detection system</article-title>,&#x201D; <source>Appl. Sci.</source>, vol. <volume>13</volume>, no. <issue>8</issue>, pp. <fpage>4921</fpage>, <year>Apr. 2023</year>. doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3390/app13084921">10.3390/app13084921</ext-link>.</mixed-citation></ref>
<ref id="ref-16"><label>16</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>H.</given-names> <surname>Xie</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Hao</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Li</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Li</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Luo</surname></string-name> and <string-name><given-names>J.</given-names> <surname>Zhu</surname></string-name></person-group>, &#x201C;<article-title>Anomaly detection for time series data based on multi-granularity neighbor residual network</article-title>,&#x201D; <source>Int. J. Cogn. Comput. Eng.</source>, vol. <volume>3</volume>, no. <issue>3</issue>, pp. <fpage>180</fpage>&#x2013;<lpage>187</lpage>, <year>Jun. 2022</year>. doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.ijcce.2022.10.001">10.1016/j.ijcce.2022.10.001</ext-link>.</mixed-citation></ref>
<ref id="ref-17"><label>17</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J.</given-names> <surname>Yin</surname></string-name> <etal>et al.</etal></person-group>, &#x201C;<article-title>Internet of things intrusion detection system based on convolutional neural network</article-title>,&#x201D; <source>CMC-Comput. Mater. Contin.</source>, vol. <volume>75</volume>, no. <issue>1</issue>, pp. <fpage>2119</fpage>&#x2013;<lpage>2135</lpage>, <year>Mar. 2023</year>. doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.32604/cmc.2023.035077">10.32604/cmc.2023.035077</ext-link>.</mixed-citation></ref>
<ref id="ref-18"><label>18</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>D. S.</given-names> <surname>Terzi</surname></string-name></person-group>, &#x201C;<article-title>Gramian angular field transformation-based intrusion detection</article-title>,&#x201D; <source>Comput. Sci.</source>, vol. <volume>23</volume>, no. <issue>4</issue>, pp. <fpage>571</fpage>&#x2013;<lpage>585</lpage>, <year>Dec. 2022</year>. doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.7494/csci.2022.23.4.4406">10.7494/csci.2022.23.4.4406</ext-link>.</mixed-citation></ref>
<ref id="ref-19"><label>19</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>G.</given-names> <surname>Baldini</surname></string-name>, <string-name><given-names>J. L.</given-names> <surname>Hernandez Ramos</surname></string-name>, and <string-name><given-names>I.</given-names> <surname>Amerini</surname></string-name></person-group>, &#x201C;<article-title>Intrusion detection based on gray-level co-occurrence matrix and 2D dispersion entropy</article-title>,&#x201D; <source>Appl. Sci.</source>, vol. <volume>11</volume>, no. <issue>2</issue>, pp. <fpage>5567</fpage>, <year>Jun. 2021</year>. doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3390/app11125567">10.3390/app11125567</ext-link>.</mixed-citation></ref>
<ref id="ref-20"><label>20</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. A.</given-names> <surname>Siddiqi</surname></string-name> and <string-name><given-names>W.</given-names> <surname>Pak</surname></string-name></person-group>, &#x201C;<article-title>Tier-based optimization for synthesized network intrusion detection system</article-title>,&#x201D; <source>IEEE Access</source>, vol. <volume>10</volume>, no. <issue>13</issue>, pp. <fpage>108530</fpage>&#x2013;<lpage>108544</lpage>, <year>Oct. 2022</year>. doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1109/ACCESS.2022.3213937">10.1109/ACCESS.2022.3213937</ext-link>.</mixed-citation></ref>
<ref id="ref-21"><label>21</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>G. I.</given-names> <surname>Webb</surname></string-name> and <string-name><given-names>Z.</given-names> <surname>Zheng</surname></string-name></person-group>, &#x201C;<article-title>Multistrategy ensemble learning: Reducing error by combining ensemble learning techniques</article-title>,&#x201D; <source>IEEE Trans. Knowl. Data Eng.</source>, vol. <volume>16</volume>, no. <issue>8</issue>, pp. <fpage>980</fpage>&#x2013;<lpage>991</lpage>, <year>Aug. 2004</year>. doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1109/TKDE.2004.29">10.1109/TKDE.2004.29</ext-link>.</mixed-citation></ref>
<ref id="ref-22"><label>22</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Y.</given-names> <surname>Shen</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Zheng</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Yang</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Liu</surname></string-name>, and <string-name><given-names>M.</given-names> <surname>Huang</surname></string-name></person-group>, &#x201C;<article-title>CBA-CLSVE: A class-level soft-voting ensemble based on the chaos bat algorithm for intrusion detection</article-title>,&#x201D; <source>Appl. Sci.</source>, vol. <volume>12</volume>, pp. <fpage>21</fpage>, <year>Nov. 2022</year>. doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3390/app122111298">10.3390/app122111298</ext-link>.</mixed-citation></ref>
<ref id="ref-23"><label>23</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>H.</given-names> <surname>Alshede</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Nassef</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Alowidi</surname></string-name>, and <string-name><given-names>E.</given-names> <surname>Fadel</surname></string-name></person-group>, &#x201C;<article-title>Ensemble voting-based anomaly detection for a smart grid communication infrastructure</article-title>,&#x201D; <source>Intell. Auto. Soft Comput.</source>, vol. <volume>36</volume>, no. <issue>3</issue>, pp. <fpage>3257</fpage>&#x2013;<lpage>3278</lpage>, <year>Jun. 2023</year>. doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.32604/iasc.2023.035874">10.32604/iasc.2023.035874</ext-link>.</mixed-citation></ref>
<ref id="ref-24"><label>24</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>D.</given-names> <surname>Albashish</surname></string-name> and <string-name><given-names>A.</given-names> <surname>Aburomman</surname></string-name></person-group>, &#x201C;<article-title>Weighted heterogeneous ensemble for the classification of intrusion detection using ant colony optimization for continuous search spaces</article-title>,&#x201D; <source>Soft Comput.</source>, vol. <volume>27</volume>, no. <issue>8</issue>, pp. <fpage>4779</fpage>&#x2013;<lpage>4793</lpage>, <year>Nov. 2022</year>. doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s00500-022-07612-9">10.1007/s00500-022-07612-9</ext-link>.</mixed-citation></ref>
<ref id="ref-25"><label>25</label><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><given-names>L.</given-names> <surname>Liu</surname></string-name> and <string-name><given-names>Z.</given-names> <surname>Wang</surname></string-name></person-group>, &#x201C;<article-title>Encoding temporal markov dynamics in graph for time series visualization</article-title>,&#x201D; <source>arXiv preprint arXiv</source>. <comment>2016. 1610.07273</comment>.</mixed-citation></ref>
<ref id="ref-26"><label>26</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Z.</given-names> <surname>Gui</surname></string-name> and <string-name><given-names>Y.</given-names> <surname>Liu</surname></string-name></person-group>, &#x201C;<article-title>An image sharpening algorithm based on fuzzy logic</article-title>,&#x201D; <source>Optik</source>, vol. <volume>122</volume>, no. <issue>8</issue>, pp. <fpage>697</fpage>&#x2013;<lpage>702</lpage>, <year>Jan. 2011</year>. doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.ijleo.2010.05.010">10.1016/j.ijleo.2010.05.010</ext-link>.</mixed-citation></ref>
<ref id="ref-27"><label>27</label><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><given-names>K.</given-names> <surname>Simonyan</surname></string-name> and <string-name><given-names>A.</given-names> <surname>Zisserman</surname></string-name></person-group>, &#x201C;<article-title>Very deep convolutional networks for large-scale image recognition</article-title>,&#x201D; <source>arXiv preprint arXiv</source>. <comment>2014. 1409.1556</comment>.</mixed-citation></ref>
<ref id="ref-28"><label>28</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names> <surname>Shafiq</surname></string-name> and <string-name><given-names>Z. Q.</given-names> <surname>Gu</surname></string-name></person-group>, &#x201C;<article-title>Deep residual learning for image recognition: A survey</article-title>,&#x201D; <source>Appl. Sci.-Basel</source>, vol. <volume>12</volume>, no. <issue>18</issue>, pp. <fpage>8972</fpage>, <year>Sep. 2022</year>. doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3390/app12188972">10.3390/app12188972</ext-link>.</mixed-citation></ref>
<ref id="ref-29"><label>29</label><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><given-names>A. G.</given-names> <surname>Howard</surname></string-name> <etal>et al.</etal></person-group>, &#x201C;<article-title>Mobilenets: Efficient convolutional neural networks for mobile vision applications</article-title>,&#x201D; <source>arXiv preprint arXiv</source>. <comment>2017, 1704.04861</comment>.</mixed-citation></ref>
</ref-list>
</back>
</article>
